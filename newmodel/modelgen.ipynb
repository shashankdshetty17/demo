{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import LinearSVC\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import ExtraTreeClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "pd.set_option('max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('fake reviews dataset.csv', names=['category', 'rating', 'label', 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>category</td>\n",
       "      <td>rating</td>\n",
       "      <td>label</td>\n",
       "      <td>text_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>Love this!  Well made, sturdy, and very comfortable.  I love it!Very pretty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>love it, a great upgrade from the original.  I've had mine for a couple of years</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>This pillow saved my back. I love the look and feel of this pillow.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>Missing information on how to use it, but it is a great product for the price!  I</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             category  rating  label  \\\n",
       "0            category  rating  label   \n",
       "1  Home_and_Kitchen_5     5.0     CG   \n",
       "2  Home_and_Kitchen_5     5.0     CG   \n",
       "3  Home_and_Kitchen_5     5.0     CG   \n",
       "4  Home_and_Kitchen_5     1.0     CG   \n",
       "\n",
       "                                                                                text  \n",
       "0                                                                              text_  \n",
       "1        Love this!  Well made, sturdy, and very comfortable.  I love it!Very pretty  \n",
       "2   love it, a great upgrade from the original.  I've had mine for a couple of years  \n",
       "3                This pillow saved my back. I love the look and feel of this pillow.  \n",
       "4  Missing information on how to use it, but it is a great product for the price!  I  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "OR       20358\n",
       "CG       20236\n",
       "label        1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    20359\n",
       "1    20236\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'] = df['text'].str.replace('\\n', ' ')\n",
    "df['target'] = np.where(df['label']=='CG', 1, 0)\n",
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def punctuation_to_features(df, column):\n",
    "    \"\"\"Identify punctuation within a column and convert to a text representation.\n",
    "    \n",
    "    Args:\n",
    "        df (object): Pandas dataframe.\n",
    "        column (string): Name of column containing text. \n",
    "        \n",
    "    Returns:\n",
    "        df[column]: Original column with punctuation converted to text, \n",
    "                    i.e. \"Wow! > \"Wow exclamation\"\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    df[column] = df[column].replace('!', ' exclamation ')\n",
    "    df[column] = df[column].replace('?', ' question ')\n",
    "    df[column] = df[column].replace('\\'', ' quotation ')\n",
    "    df[column] = df[column].replace('\\\"', ' quotation ')\n",
    "    \n",
    "    return df[column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = punctuation_to_features(df, 'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\shashank.shetty\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt');\n",
    "\n",
    "def tokenize(column):\n",
    "    \"\"\"Tokenizes a Pandas dataframe column and returns a list of tokens.\n",
    "    \n",
    "    Args:\n",
    "        column: Pandas dataframe column (i.e. df['text']).\n",
    "    \n",
    "    Returns:\n",
    "        tokens (list): Tokenized list, i.e. [Donald, Trump, tweets]\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    tokens = nltk.word_tokenize(column)\n",
    "    return [w for w in tokens if w.isalpha()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>category</td>\n",
       "      <td>rating</td>\n",
       "      <td>label</td>\n",
       "      <td>text_</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>Love this!  Well made, sturdy, and very comfortable.  I love it!Very pretty</td>\n",
       "      <td>1</td>\n",
       "      <td>[Love, this, Well, made, sturdy, and, very, comfortable, I, love, it, Very, pretty]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>love it, a great upgrade from the original.  I've had mine for a couple of years</td>\n",
       "      <td>1</td>\n",
       "      <td>[love, it, a, great, upgrade, from, the, original, I, had, mine, for, a, couple, of, years]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>This pillow saved my back. I love the look and feel of this pillow.</td>\n",
       "      <td>1</td>\n",
       "      <td>[This, pillow, saved, my, back, I, love, the, look, and, feel, of, this, pillow]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>Missing information on how to use it, but it is a great product for the price!  I</td>\n",
       "      <td>1</td>\n",
       "      <td>[Missing, information, on, how, to, use, it, but, it, is, a, great, product, for, the, price, I]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             category  rating  label  \\\n",
       "0            category  rating  label   \n",
       "1  Home_and_Kitchen_5     5.0     CG   \n",
       "2  Home_and_Kitchen_5     5.0     CG   \n",
       "3  Home_and_Kitchen_5     5.0     CG   \n",
       "4  Home_and_Kitchen_5     1.0     CG   \n",
       "\n",
       "                                                                                text  \\\n",
       "0                                                                              text_   \n",
       "1        Love this!  Well made, sturdy, and very comfortable.  I love it!Very pretty   \n",
       "2   love it, a great upgrade from the original.  I've had mine for a couple of years   \n",
       "3                This pillow saved my back. I love the look and feel of this pillow.   \n",
       "4  Missing information on how to use it, but it is a great product for the price!  I   \n",
       "\n",
       "   target  \\\n",
       "0       0   \n",
       "1       1   \n",
       "2       1   \n",
       "3       1   \n",
       "4       1   \n",
       "\n",
       "                                                                                          tokenized  \n",
       "0                                                                                                []  \n",
       "1               [Love, this, Well, made, sturdy, and, very, comfortable, I, love, it, Very, pretty]  \n",
       "2       [love, it, a, great, upgrade, from, the, original, I, had, mine, for, a, couple, of, years]  \n",
       "3                  [This, pillow, saved, my, back, I, love, the, look, and, feel, of, this, pillow]  \n",
       "4  [Missing, information, on, how, to, use, it, but, it, is, a, great, product, for, the, price, I]  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tokenized'] = df.apply(lambda x: tokenize(x['text']), axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stopword removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\shashank.shetty\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(tokenized_column):\n",
    "    \"\"\"Return a list of tokens with English stopwords removed. \n",
    "    \n",
    "    Args:\n",
    "        column: Pandas dataframe column of tokenized data from tokenize()\n",
    "    \n",
    "    Returns:\n",
    "        tokens (list): Tokenized list with stopwords removed.\n",
    "    \n",
    "    \"\"\"\n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    return [word for word in tokenized_column if not word in stops]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>stopwords_removed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>category</td>\n",
       "      <td>rating</td>\n",
       "      <td>label</td>\n",
       "      <td>text_</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>Love this!  Well made, sturdy, and very comfortable.  I love it!Very pretty</td>\n",
       "      <td>1</td>\n",
       "      <td>[Love, this, Well, made, sturdy, and, very, comfortable, I, love, it, Very, pretty]</td>\n",
       "      <td>[Love, Well, made, sturdy, comfortable, I, love, Very, pretty]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>love it, a great upgrade from the original.  I've had mine for a couple of years</td>\n",
       "      <td>1</td>\n",
       "      <td>[love, it, a, great, upgrade, from, the, original, I, had, mine, for, a, couple, of, years]</td>\n",
       "      <td>[love, great, upgrade, original, I, mine, couple, years]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>This pillow saved my back. I love the look and feel of this pillow.</td>\n",
       "      <td>1</td>\n",
       "      <td>[This, pillow, saved, my, back, I, love, the, look, and, feel, of, this, pillow]</td>\n",
       "      <td>[This, pillow, saved, back, I, love, look, feel, pillow]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>Missing information on how to use it, but it is a great product for the price!  I</td>\n",
       "      <td>1</td>\n",
       "      <td>[Missing, information, on, how, to, use, it, but, it, is, a, great, product, for, the, price, I]</td>\n",
       "      <td>[Missing, information, use, great, product, price, I]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             category  rating  label  \\\n",
       "0            category  rating  label   \n",
       "1  Home_and_Kitchen_5     5.0     CG   \n",
       "2  Home_and_Kitchen_5     5.0     CG   \n",
       "3  Home_and_Kitchen_5     5.0     CG   \n",
       "4  Home_and_Kitchen_5     1.0     CG   \n",
       "\n",
       "                                                                                text  \\\n",
       "0                                                                              text_   \n",
       "1        Love this!  Well made, sturdy, and very comfortable.  I love it!Very pretty   \n",
       "2   love it, a great upgrade from the original.  I've had mine for a couple of years   \n",
       "3                This pillow saved my back. I love the look and feel of this pillow.   \n",
       "4  Missing information on how to use it, but it is a great product for the price!  I   \n",
       "\n",
       "   target  \\\n",
       "0       0   \n",
       "1       1   \n",
       "2       1   \n",
       "3       1   \n",
       "4       1   \n",
       "\n",
       "                                                                                          tokenized  \\\n",
       "0                                                                                                []   \n",
       "1               [Love, this, Well, made, sturdy, and, very, comfortable, I, love, it, Very, pretty]   \n",
       "2       [love, it, a, great, upgrade, from, the, original, I, had, mine, for, a, couple, of, years]   \n",
       "3                  [This, pillow, saved, my, back, I, love, the, look, and, feel, of, this, pillow]   \n",
       "4  [Missing, information, on, how, to, use, it, but, it, is, a, great, product, for, the, price, I]   \n",
       "\n",
       "                                                stopwords_removed  \n",
       "0                                                              []  \n",
       "1  [Love, Well, made, sturdy, comfortable, I, love, Very, pretty]  \n",
       "2        [love, great, upgrade, original, I, mine, couple, years]  \n",
       "3        [This, pillow, saved, back, I, love, look, feel, pillow]  \n",
       "4           [Missing, information, use, great, product, price, I]  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['stopwords_removed'] = df.apply(lambda x: remove_stopwords(x['tokenized']), axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply Porter stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_stemming(tokenized_column):\n",
    "    \"\"\"Return a list of tokens with Porter stemming applied.\n",
    "    \n",
    "    Args:\n",
    "        column: Pandas dataframe column of tokenized data with stopwords removed.\n",
    "    \n",
    "    Returns:\n",
    "        tokens (list): Tokenized list with words Porter stemmed.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    stemmer = PorterStemmer() \n",
    "    return [stemmer.stem(word).lower() for word in tokenized_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>stopwords_removed</th>\n",
       "      <th>porter_stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>category</td>\n",
       "      <td>rating</td>\n",
       "      <td>label</td>\n",
       "      <td>text_</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>Love this!  Well made, sturdy, and very comfortable.  I love it!Very pretty</td>\n",
       "      <td>1</td>\n",
       "      <td>[Love, this, Well, made, sturdy, and, very, comfortable, I, love, it, Very, pretty]</td>\n",
       "      <td>[Love, Well, made, sturdy, comfortable, I, love, Very, pretty]</td>\n",
       "      <td>[love, well, made, sturdi, comfort, i, love, veri, pretti]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>love it, a great upgrade from the original.  I've had mine for a couple of years</td>\n",
       "      <td>1</td>\n",
       "      <td>[love, it, a, great, upgrade, from, the, original, I, had, mine, for, a, couple, of, years]</td>\n",
       "      <td>[love, great, upgrade, original, I, mine, couple, years]</td>\n",
       "      <td>[love, great, upgrad, origin, i, mine, coupl, year]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>This pillow saved my back. I love the look and feel of this pillow.</td>\n",
       "      <td>1</td>\n",
       "      <td>[This, pillow, saved, my, back, I, love, the, look, and, feel, of, this, pillow]</td>\n",
       "      <td>[This, pillow, saved, back, I, love, look, feel, pillow]</td>\n",
       "      <td>[thi, pillow, save, back, i, love, look, feel, pillow]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>Missing information on how to use it, but it is a great product for the price!  I</td>\n",
       "      <td>1</td>\n",
       "      <td>[Missing, information, on, how, to, use, it, but, it, is, a, great, product, for, the, price, I]</td>\n",
       "      <td>[Missing, information, use, great, product, price, I]</td>\n",
       "      <td>[miss, inform, use, great, product, price, i]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             category  rating  label  \\\n",
       "0            category  rating  label   \n",
       "1  Home_and_Kitchen_5     5.0     CG   \n",
       "2  Home_and_Kitchen_5     5.0     CG   \n",
       "3  Home_and_Kitchen_5     5.0     CG   \n",
       "4  Home_and_Kitchen_5     1.0     CG   \n",
       "\n",
       "                                                                                text  \\\n",
       "0                                                                              text_   \n",
       "1        Love this!  Well made, sturdy, and very comfortable.  I love it!Very pretty   \n",
       "2   love it, a great upgrade from the original.  I've had mine for a couple of years   \n",
       "3                This pillow saved my back. I love the look and feel of this pillow.   \n",
       "4  Missing information on how to use it, but it is a great product for the price!  I   \n",
       "\n",
       "   target  \\\n",
       "0       0   \n",
       "1       1   \n",
       "2       1   \n",
       "3       1   \n",
       "4       1   \n",
       "\n",
       "                                                                                          tokenized  \\\n",
       "0                                                                                                []   \n",
       "1               [Love, this, Well, made, sturdy, and, very, comfortable, I, love, it, Very, pretty]   \n",
       "2       [love, it, a, great, upgrade, from, the, original, I, had, mine, for, a, couple, of, years]   \n",
       "3                  [This, pillow, saved, my, back, I, love, the, look, and, feel, of, this, pillow]   \n",
       "4  [Missing, information, on, how, to, use, it, but, it, is, a, great, product, for, the, price, I]   \n",
       "\n",
       "                                                stopwords_removed  \\\n",
       "0                                                              []   \n",
       "1  [Love, Well, made, sturdy, comfortable, I, love, Very, pretty]   \n",
       "2        [love, great, upgrade, original, I, mine, couple, years]   \n",
       "3        [This, pillow, saved, back, I, love, look, feel, pillow]   \n",
       "4           [Missing, information, use, great, product, price, I]   \n",
       "\n",
       "                                               porter_stemmed  \n",
       "0                                                          []  \n",
       "1  [love, well, made, sturdi, comfort, i, love, veri, pretti]  \n",
       "2         [love, great, upgrad, origin, i, mine, coupl, year]  \n",
       "3      [thi, pillow, save, back, i, love, look, feel, pillow]  \n",
       "4               [miss, inform, use, great, product, price, i]  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['porter_stemmed'] = df.apply(lambda x: apply_stemming(x['stopwords_removed']), axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rejoin words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rejoin_words(tokenized_column):\n",
    "    return ( \" \".join(tokenized_column))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>love well made sturdi comfort i love veri pretti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>love great upgrad origin i mine coupl year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>thi pillow save back i love look feel pillow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>miss inform use great product price i</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           all_text\n",
       "0                                                  \n",
       "1  love well made sturdi comfort i love veri pretti\n",
       "2        love great upgrad origin i mine coupl year\n",
       "3      thi pillow save back i love look feel pillow\n",
       "4             miss inform use great product price i"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['all_text'] = df.apply(lambda x: rejoin_words(x['porter_stemmed']), axis=1)\n",
    "df[['all_text']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['all_text']\n",
    "y = df['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {}\n",
    "classifiers.update({\"XGBClassifier\": XGBClassifier(eval_metric='logloss',objective='binary:logistic',)})\n",
    "classifiers.update({\"CatBoostClassifier\": CatBoostClassifier(silent=True)})\n",
    "classifiers.update({\"LinearSVC\": LinearSVC()})\n",
    "classifiers.update({\"MultinomialNB\": MultinomialNB()})\n",
    "classifiers.update({\"LGBMClassifier\": LGBMClassifier()})\n",
    "classifiers.update({\"RandomForestClassifier\": RandomForestClassifier()})\n",
    "classifiers.update({\"DecisionTreeClassifier\": DecisionTreeClassifier()})\n",
    "classifiers.update({\"ExtraTreeClassifier\": ExtraTreeClassifier()})\n",
    "classifiers.update({\"AdaBoostClassifier\": AdaBoostClassifier()})\n",
    "classifiers.update({\"KNeighborsClassifier\": KNeighborsClassifier()})\n",
    "classifiers.update({\"RidgeClassifier\": RidgeClassifier()})\n",
    "classifiers.update({\"SGDClassifier\": SGDClassifier()})\n",
    "classifiers.update({\"BaggingClassifier\": BaggingClassifier()})\n",
    "classifiers.update({\"BernoulliNB\": BernoulliNB()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_models = pd.DataFrame(columns=['model', 'run_time', 'roc_auc', 'roc_auc_std'])\n",
    "\n",
    "for key in classifiers:\n",
    "    \n",
    "    start_time = time.time()\n",
    "    pipeline = Pipeline([(\"tfidf\", TfidfVectorizer()), (\"clf\", classifiers[key] )])\n",
    "    cv = cross_val_score(pipeline, X, y, cv=5, scoring='roc_auc')\n",
    "\n",
    "    row = {'model': key,\n",
    "           'run_time': format(round((time.time() - start_time)/60,2)),\n",
    "           'roc_auc': cv.mean(),\n",
    "           'roc_auc_std': cv.std(),\n",
    "    }\n",
    "    \n",
    "    df_models = pd.concat([df_models, pd.DataFrame(row, index=[0])], ignore_index=True)\n",
    "    \n",
    "df_models = df_models.sort_values(by='roc_auc', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>run_time</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>roc_auc_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.924304</td>\n",
       "      <td>0.009017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CatBoostClassifier</td>\n",
       "      <td>11.14</td>\n",
       "      <td>0.922078</td>\n",
       "      <td>0.010460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.921062</td>\n",
       "      <td>0.013086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RidgeClassifier</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.920814</td>\n",
       "      <td>0.013822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.917614</td>\n",
       "      <td>0.011333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.914757</td>\n",
       "      <td>0.010398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>8.13</td>\n",
       "      <td>0.912112</td>\n",
       "      <td>0.015514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.900591</td>\n",
       "      <td>0.020190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>16.78</td>\n",
       "      <td>0.857346</td>\n",
       "      <td>0.011597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.842195</td>\n",
       "      <td>0.021487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>BernoulliNB</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.827052</td>\n",
       "      <td>0.021919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>1.19</td>\n",
       "      <td>0.736338</td>\n",
       "      <td>0.009431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>1.33</td>\n",
       "      <td>0.699702</td>\n",
       "      <td>0.036905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ExtraTreeClassifier</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.667977</td>\n",
       "      <td>0.016583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     model run_time   roc_auc  roc_auc_std\n",
       "11           SGDClassifier     0.05  0.924304     0.009017\n",
       "1       CatBoostClassifier    11.14  0.922078     0.010460\n",
       "2                LinearSVC     0.06  0.921062     0.013086\n",
       "10         RidgeClassifier     0.06  0.920814     0.013822\n",
       "4           LGBMClassifier     0.28  0.917614     0.011333\n",
       "0            XGBClassifier     0.49  0.914757     0.010398\n",
       "5   RandomForestClassifier     8.13  0.912112     0.015514\n",
       "3            MultinomialNB     0.05  0.900591     0.020190\n",
       "12       BaggingClassifier    16.78  0.857346     0.011597\n",
       "8       AdaBoostClassifier     0.66  0.842195     0.021487\n",
       "13             BernoulliNB     0.08  0.827052     0.021919\n",
       "6   DecisionTreeClassifier     1.19  0.736338     0.009431\n",
       "9     KNeighborsClassifier     1.33  0.699702     0.036905\n",
       "7      ExtraTreeClassifier     0.18  0.667977     0.016583"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SGDClassifier',\n",
       " 'CatBoostClassifier',\n",
       " 'LinearSVC',\n",
       " 'RidgeClassifier',\n",
       " 'LGBMClassifier',\n",
       " 'XGBClassifier',\n",
       " 'RandomForestClassifier',\n",
       " 'MultinomialNB',\n",
       " 'BaggingClassifier',\n",
       " 'AdaBoostClassifier']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_ten = df_models[\"model\"].head(10).values.tolist()\n",
    "top_ten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assess the selected model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in top_ten:\n",
    "    pipeline = Pipeline([(\"tfidf\", TfidfVectorizer()), (\"clf\", classifiers[key])])\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    model_name = f\"MODEL/{key}_model.pkl\"\n",
    "    pickle.dump(pipeline, open(model_name,'wb'))\n",
    "#y_pred = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "SGDClassifier\n",
      "----------------------------\n",
      "Accuracy: 0.8688726496428278\n",
      "Precision: 0.8859289617486339\n",
      "Recall: 0.8481281674023214\n",
      "ROC/AUC: 0.868966756086512\n",
      "----------------------------\n",
      "CatBoostClassifier\n",
      "----------------------------\n",
      "Accuracy: 0.8629608342228426\n",
      "Precision: 0.876056814338857\n",
      "Recall: 0.8469838155958803\n",
      "ROC/AUC: 0.8630333132746806\n",
      "----------------------------\n",
      "LinearSVC\n",
      "----------------------------\n",
      "Accuracy: 0.8747023565153133\n",
      "Precision: 0.8737990555284155\n",
      "Recall: 0.8772273990518228\n",
      "ROC/AUC: 0.8746909017693953\n",
      "----------------------------\n",
      "RidgeClassifier\n",
      "----------------------------\n",
      "Accuracy: 0.8745381394203137\n",
      "Precision: 0.8769508789222934\n",
      "Recall: 0.8726499918260585\n",
      "ROC/AUC: 0.8745467049199578\n",
      "----------------------------\n",
      "LGBMClassifier\n",
      "----------------------------\n",
      "Accuracy: 0.8560637162328598\n",
      "Precision: 0.860899768441945\n",
      "Recall: 0.8509073075036783\n",
      "ROC/AUC: 0.8560871080573489\n",
      "----------------------------\n",
      "XGBClassifier\n",
      "----------------------------\n",
      "Accuracy: 0.8541752196403646\n",
      "Precision: 0.8688190314358538\n",
      "Recall: 0.8358672551904528\n",
      "ROC/AUC: 0.8542582729268\n",
      "----------------------------\n",
      "RandomForestClassifier\n",
      "----------------------------\n",
      "Accuracy: 0.857623778635356\n",
      "Precision: 0.8392940083604273\n",
      "Recall: 0.8862187346738597\n",
      "ROC/AUC: 0.8574940588578801\n",
      "----------------------------\n",
      "MultinomialNB\n",
      "----------------------------\n",
      "Accuracy: 0.8393956810904015\n",
      "Precision: 0.8085421919027139\n",
      "Recall: 0.8912865783880988\n",
      "ROC/AUC: 0.8391602802860982\n",
      "----------------------------\n",
      "BaggingClassifier\n",
      "----------------------------\n",
      "Accuracy: 0.8057311766154857\n",
      "Precision: 0.8122190777426336\n",
      "Recall: 0.7976132090894229\n",
      "ROC/AUC: 0.8057680034229694\n",
      "----------------------------\n",
      "AdaBoostClassifier\n",
      "----------------------------\n",
      "Accuracy: 0.7854503653830364\n",
      "Precision: 0.7924874791318864\n",
      "Recall: 0.7760340035965343\n",
      "ROC/AUC: 0.7854930822997517\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "\n",
    "for i in top_ten:\n",
    "    pipeline = pickle.load(open(f\"MODEL/{i}_model.pkl\", 'rb'))\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    print(\"----------------------------\")\n",
    "    print(i)\n",
    "    print(\"----------------------------\")\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred)\n",
    "    rec = recall_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred)\n",
    "    print('Accuracy:', acc)\n",
    "    print('Precision:', prec)\n",
    "    print('Recall:', rec)\n",
    "    print('ROC/AUC:', roc_auc)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
