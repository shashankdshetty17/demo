{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import LinearSVC\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import ExtraTreeClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "pd.set_option('max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('fake reviews dataset.csv', names=['category', 'rating', 'label', 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>category</td>\n",
       "      <td>rating</td>\n",
       "      <td>label</td>\n",
       "      <td>text_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>Love this!  Well made, sturdy, and very comfortable.  I love it!Very pretty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>love it, a great upgrade from the original.  I've had mine for a couple of years</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>This pillow saved my back. I love the look and feel of this pillow.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>Missing information on how to use it, but it is a great product for the price!  I</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             category  rating  label  \\\n",
       "0            category  rating  label   \n",
       "1  Home_and_Kitchen_5     5.0     CG   \n",
       "2  Home_and_Kitchen_5     5.0     CG   \n",
       "3  Home_and_Kitchen_5     5.0     CG   \n",
       "4  Home_and_Kitchen_5     1.0     CG   \n",
       "\n",
       "                                                                                text  \n",
       "0                                                                              text_  \n",
       "1        Love this!  Well made, sturdy, and very comfortable.  I love it!Very pretty  \n",
       "2   love it, a great upgrade from the original.  I've had mine for a couple of years  \n",
       "3                This pillow saved my back. I love the look and feel of this pillow.  \n",
       "4  Missing information on how to use it, but it is a great product for the price!  I  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OR       20358\n",
       "CG       20236\n",
       "label        1\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    20359\n",
       "1    20236\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'] = df['text'].str.replace('\\n', ' ')\n",
    "df['target'] = np.where(df['label']=='CG', 1, 0)\n",
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def punctuation_to_features(df, column):\n",
    "    \"\"\"Identify punctuation within a column and convert to a text representation.\n",
    "    \n",
    "    Args:\n",
    "        df (object): Pandas dataframe.\n",
    "        column (string): Name of column containing text. \n",
    "        \n",
    "    Returns:\n",
    "        df[column]: Original column with punctuation converted to text, \n",
    "                    i.e. \"Wow! > \"Wow exclamation\"\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    df[column] = df[column].replace('!', ' exclamation ')\n",
    "    df[column] = df[column].replace('?', ' question ')\n",
    "    df[column] = df[column].replace('\\'', ' quotation ')\n",
    "    df[column] = df[column].replace('\\\"', ' quotation ')\n",
    "    \n",
    "    return df[column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = punctuation_to_features(df, 'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\shash\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt');\n",
    "\n",
    "def tokenize(column):\n",
    "    \"\"\"Tokenizes a Pandas dataframe column and returns a list of tokens.\n",
    "    \n",
    "    Args:\n",
    "        column: Pandas dataframe column (i.e. df['text']).\n",
    "    \n",
    "    Returns:\n",
    "        tokens (list): Tokenized list, i.e. [Donald, Trump, tweets]\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    tokens = nltk.word_tokenize(column)\n",
    "    return [w for w in tokens if w.isalpha()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>category</td>\n",
       "      <td>rating</td>\n",
       "      <td>label</td>\n",
       "      <td>text_</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>Love this!  Well made, sturdy, and very comfortable.  I love it!Very pretty</td>\n",
       "      <td>1</td>\n",
       "      <td>[Love, this, Well, made, sturdy, and, very, comfortable, I, love, it, Very, pretty]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>love it, a great upgrade from the original.  I've had mine for a couple of years</td>\n",
       "      <td>1</td>\n",
       "      <td>[love, it, a, great, upgrade, from, the, original, I, had, mine, for, a, couple, of, years]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>This pillow saved my back. I love the look and feel of this pillow.</td>\n",
       "      <td>1</td>\n",
       "      <td>[This, pillow, saved, my, back, I, love, the, look, and, feel, of, this, pillow]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>Missing information on how to use it, but it is a great product for the price!  I</td>\n",
       "      <td>1</td>\n",
       "      <td>[Missing, information, on, how, to, use, it, but, it, is, a, great, product, for, the, price, I]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             category  rating  label  \\\n",
       "0            category  rating  label   \n",
       "1  Home_and_Kitchen_5     5.0     CG   \n",
       "2  Home_and_Kitchen_5     5.0     CG   \n",
       "3  Home_and_Kitchen_5     5.0     CG   \n",
       "4  Home_and_Kitchen_5     1.0     CG   \n",
       "\n",
       "                                                                                text  \\\n",
       "0                                                                              text_   \n",
       "1        Love this!  Well made, sturdy, and very comfortable.  I love it!Very pretty   \n",
       "2   love it, a great upgrade from the original.  I've had mine for a couple of years   \n",
       "3                This pillow saved my back. I love the look and feel of this pillow.   \n",
       "4  Missing information on how to use it, but it is a great product for the price!  I   \n",
       "\n",
       "   target  \\\n",
       "0       0   \n",
       "1       1   \n",
       "2       1   \n",
       "3       1   \n",
       "4       1   \n",
       "\n",
       "                                                                                          tokenized  \n",
       "0                                                                                                []  \n",
       "1               [Love, this, Well, made, sturdy, and, very, comfortable, I, love, it, Very, pretty]  \n",
       "2       [love, it, a, great, upgrade, from, the, original, I, had, mine, for, a, couple, of, years]  \n",
       "3                  [This, pillow, saved, my, back, I, love, the, look, and, feel, of, this, pillow]  \n",
       "4  [Missing, information, on, how, to, use, it, but, it, is, a, great, product, for, the, price, I]  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tokenized'] = df.apply(lambda x: tokenize(x['text']), axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stopword removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\shash\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(tokenized_column):\n",
    "    \"\"\"Return a list of tokens with English stopwords removed. \n",
    "    \n",
    "    Args:\n",
    "        column: Pandas dataframe column of tokenized data from tokenize()\n",
    "    \n",
    "    Returns:\n",
    "        tokens (list): Tokenized list with stopwords removed.\n",
    "    \n",
    "    \"\"\"\n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    return [word for word in tokenized_column if not word in stops]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>stopwords_removed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>category</td>\n",
       "      <td>rating</td>\n",
       "      <td>label</td>\n",
       "      <td>text_</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>Love this!  Well made, sturdy, and very comfortable.  I love it!Very pretty</td>\n",
       "      <td>1</td>\n",
       "      <td>[Love, this, Well, made, sturdy, and, very, comfortable, I, love, it, Very, pretty]</td>\n",
       "      <td>[Love, Well, made, sturdy, comfortable, I, love, Very, pretty]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>love it, a great upgrade from the original.  I've had mine for a couple of years</td>\n",
       "      <td>1</td>\n",
       "      <td>[love, it, a, great, upgrade, from, the, original, I, had, mine, for, a, couple, of, years]</td>\n",
       "      <td>[love, great, upgrade, original, I, mine, couple, years]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>This pillow saved my back. I love the look and feel of this pillow.</td>\n",
       "      <td>1</td>\n",
       "      <td>[This, pillow, saved, my, back, I, love, the, look, and, feel, of, this, pillow]</td>\n",
       "      <td>[This, pillow, saved, back, I, love, look, feel, pillow]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>Missing information on how to use it, but it is a great product for the price!  I</td>\n",
       "      <td>1</td>\n",
       "      <td>[Missing, information, on, how, to, use, it, but, it, is, a, great, product, for, the, price, I]</td>\n",
       "      <td>[Missing, information, use, great, product, price, I]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             category  rating  label  \\\n",
       "0            category  rating  label   \n",
       "1  Home_and_Kitchen_5     5.0     CG   \n",
       "2  Home_and_Kitchen_5     5.0     CG   \n",
       "3  Home_and_Kitchen_5     5.0     CG   \n",
       "4  Home_and_Kitchen_5     1.0     CG   \n",
       "\n",
       "                                                                                text  \\\n",
       "0                                                                              text_   \n",
       "1        Love this!  Well made, sturdy, and very comfortable.  I love it!Very pretty   \n",
       "2   love it, a great upgrade from the original.  I've had mine for a couple of years   \n",
       "3                This pillow saved my back. I love the look and feel of this pillow.   \n",
       "4  Missing information on how to use it, but it is a great product for the price!  I   \n",
       "\n",
       "   target  \\\n",
       "0       0   \n",
       "1       1   \n",
       "2       1   \n",
       "3       1   \n",
       "4       1   \n",
       "\n",
       "                                                                                          tokenized  \\\n",
       "0                                                                                                []   \n",
       "1               [Love, this, Well, made, sturdy, and, very, comfortable, I, love, it, Very, pretty]   \n",
       "2       [love, it, a, great, upgrade, from, the, original, I, had, mine, for, a, couple, of, years]   \n",
       "3                  [This, pillow, saved, my, back, I, love, the, look, and, feel, of, this, pillow]   \n",
       "4  [Missing, information, on, how, to, use, it, but, it, is, a, great, product, for, the, price, I]   \n",
       "\n",
       "                                                stopwords_removed  \n",
       "0                                                              []  \n",
       "1  [Love, Well, made, sturdy, comfortable, I, love, Very, pretty]  \n",
       "2        [love, great, upgrade, original, I, mine, couple, years]  \n",
       "3        [This, pillow, saved, back, I, love, look, feel, pillow]  \n",
       "4           [Missing, information, use, great, product, price, I]  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['stopwords_removed'] = df.apply(lambda x: remove_stopwords(x['tokenized']), axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply Porter stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_stemming(tokenized_column):\n",
    "    \"\"\"Return a list of tokens with Porter stemming applied.\n",
    "    \n",
    "    Args:\n",
    "        column: Pandas dataframe column of tokenized data with stopwords removed.\n",
    "    \n",
    "    Returns:\n",
    "        tokens (list): Tokenized list with words Porter stemmed.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    stemmer = PorterStemmer() \n",
    "    return [stemmer.stem(word).lower() for word in tokenized_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>stopwords_removed</th>\n",
       "      <th>porter_stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>category</td>\n",
       "      <td>rating</td>\n",
       "      <td>label</td>\n",
       "      <td>text_</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>Love this!  Well made, sturdy, and very comfortable.  I love it!Very pretty</td>\n",
       "      <td>1</td>\n",
       "      <td>[Love, this, Well, made, sturdy, and, very, comfortable, I, love, it, Very, pretty]</td>\n",
       "      <td>[Love, Well, made, sturdy, comfortable, I, love, Very, pretty]</td>\n",
       "      <td>[love, well, made, sturdi, comfort, i, love, veri, pretti]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>love it, a great upgrade from the original.  I've had mine for a couple of years</td>\n",
       "      <td>1</td>\n",
       "      <td>[love, it, a, great, upgrade, from, the, original, I, had, mine, for, a, couple, of, years]</td>\n",
       "      <td>[love, great, upgrade, original, I, mine, couple, years]</td>\n",
       "      <td>[love, great, upgrad, origin, i, mine, coupl, year]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>This pillow saved my back. I love the look and feel of this pillow.</td>\n",
       "      <td>1</td>\n",
       "      <td>[This, pillow, saved, my, back, I, love, the, look, and, feel, of, this, pillow]</td>\n",
       "      <td>[This, pillow, saved, back, I, love, look, feel, pillow]</td>\n",
       "      <td>[thi, pillow, save, back, i, love, look, feel, pillow]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>Missing information on how to use it, but it is a great product for the price!  I</td>\n",
       "      <td>1</td>\n",
       "      <td>[Missing, information, on, how, to, use, it, but, it, is, a, great, product, for, the, price, I]</td>\n",
       "      <td>[Missing, information, use, great, product, price, I]</td>\n",
       "      <td>[miss, inform, use, great, product, price, i]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             category  rating  label  \\\n",
       "0            category  rating  label   \n",
       "1  Home_and_Kitchen_5     5.0     CG   \n",
       "2  Home_and_Kitchen_5     5.0     CG   \n",
       "3  Home_and_Kitchen_5     5.0     CG   \n",
       "4  Home_and_Kitchen_5     1.0     CG   \n",
       "\n",
       "                                                                                text  \\\n",
       "0                                                                              text_   \n",
       "1        Love this!  Well made, sturdy, and very comfortable.  I love it!Very pretty   \n",
       "2   love it, a great upgrade from the original.  I've had mine for a couple of years   \n",
       "3                This pillow saved my back. I love the look and feel of this pillow.   \n",
       "4  Missing information on how to use it, but it is a great product for the price!  I   \n",
       "\n",
       "   target  \\\n",
       "0       0   \n",
       "1       1   \n",
       "2       1   \n",
       "3       1   \n",
       "4       1   \n",
       "\n",
       "                                                                                          tokenized  \\\n",
       "0                                                                                                []   \n",
       "1               [Love, this, Well, made, sturdy, and, very, comfortable, I, love, it, Very, pretty]   \n",
       "2       [love, it, a, great, upgrade, from, the, original, I, had, mine, for, a, couple, of, years]   \n",
       "3                  [This, pillow, saved, my, back, I, love, the, look, and, feel, of, this, pillow]   \n",
       "4  [Missing, information, on, how, to, use, it, but, it, is, a, great, product, for, the, price, I]   \n",
       "\n",
       "                                                stopwords_removed  \\\n",
       "0                                                              []   \n",
       "1  [Love, Well, made, sturdy, comfortable, I, love, Very, pretty]   \n",
       "2        [love, great, upgrade, original, I, mine, couple, years]   \n",
       "3        [This, pillow, saved, back, I, love, look, feel, pillow]   \n",
       "4           [Missing, information, use, great, product, price, I]   \n",
       "\n",
       "                                               porter_stemmed  \n",
       "0                                                          []  \n",
       "1  [love, well, made, sturdi, comfort, i, love, veri, pretti]  \n",
       "2         [love, great, upgrad, origin, i, mine, coupl, year]  \n",
       "3      [thi, pillow, save, back, i, love, look, feel, pillow]  \n",
       "4               [miss, inform, use, great, product, price, i]  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['porter_stemmed'] = df.apply(lambda x: apply_stemming(x['stopwords_removed']), axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rejoin words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rejoin_words(tokenized_column):\n",
    "    return ( \" \".join(tokenized_column))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>love well made sturdi comfort i love veri pretti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>love great upgrad origin i mine coupl year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>thi pillow save back i love look feel pillow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>miss inform use great product price i</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           all_text\n",
       "0                                                  \n",
       "1  love well made sturdi comfort i love veri pretti\n",
       "2        love great upgrad origin i mine coupl year\n",
       "3      thi pillow save back i love look feel pillow\n",
       "4             miss inform use great product price i"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['all_text'] = df.apply(lambda x: rejoin_words(x['porter_stemmed']), axis=1)\n",
    "df[['all_text']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['all_text']\n",
    "y = df['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {}\n",
    "classifiers.update({\"XGBClassifier\": XGBClassifier(eval_metric='logloss',objective='binary:logistic',)})\n",
    "classifiers.update({\"CatBoostClassifier\": CatBoostClassifier(silent=True)})\n",
    "classifiers.update({\"LinearSVC\": LinearSVC()})\n",
    "classifiers.update({\"MultinomialNB\": MultinomialNB()})\n",
    "classifiers.update({\"LGBMClassifier\": LGBMClassifier()})\n",
    "classifiers.update({\"RandomForestClassifier\": RandomForestClassifier()})\n",
    "classifiers.update({\"DecisionTreeClassifier\": DecisionTreeClassifier()})\n",
    "classifiers.update({\"ExtraTreeClassifier\": ExtraTreeClassifier()})\n",
    "classifiers.update({\"AdaBoostClassifier\": AdaBoostClassifier()})\n",
    "classifiers.update({\"KNeighborsClassifier\": KNeighborsClassifier()})\n",
    "classifiers.update({\"RidgeClassifier\": RidgeClassifier()})\n",
    "classifiers.update({\"SGDClassifier\": SGDClassifier()})\n",
    "classifiers.update({\"BaggingClassifier\": BaggingClassifier()})\n",
    "classifiers.update({\"BernoulliNB\": BernoulliNB()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_models = pd.DataFrame(columns=['model', 'run_time', 'roc_auc', 'roc_auc_std'])\n",
    "\n",
    "for key in classifiers:\n",
    "    \n",
    "    start_time = time.time()\n",
    "    pipeline = Pipeline([(\"tfidf\", TfidfVectorizer()), (\"clf\", classifiers[key] )])\n",
    "    cv = cross_val_score(pipeline, X, y, cv=5, scoring='roc_auc')\n",
    "\n",
    "    row = {'model': key,\n",
    "           'run_time': format(round((time.time() - start_time)/60,2)),\n",
    "           'roc_auc': cv.mean(),\n",
    "           'roc_auc_std': cv.std(),\n",
    "    }\n",
    "    \n",
    "    df_models = pd.concat([df_models, pd.DataFrame(row, index=[0])], ignore_index=True)\n",
    "    \n",
    "df_models = df_models.sort_values(by='roc_auc', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>run_time</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>roc_auc_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>8.58</td>\n",
       "      <td>0.911289</td>\n",
       "      <td>0.01614</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model run_time   roc_auc roc_auc_std\n",
       "0  RandomForestClassifier     8.58  0.911289     0.01614"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RandomForestClassifier']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_ten = df_models[\"model\"].head(10).values.tolist()\n",
    "top_ten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assess the selected model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in top_ten:\n",
    "    pipeline = Pipeline([(\"tfidf\", TfidfVectorizer()), (\"clf\", classifiers[key])])\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    model_name = f\"MODEL/{key}_model.pkl\"\n",
    "    pickle.dump(pipeline, open(model_name,'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "RandomForestClassifier\n",
      "----------------------------\n",
      "Accuracy: 0.8570490188028573\n",
      "Precision: 0.8390145646110939\n",
      "Recall: 0.8852378616969102\n",
      "ROC/AUC: 0.856921141340042\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "\n",
    "for i in top_ten:\n",
    "    pipeline = pickle.load(open(f\"MODEL/{i}_model.pkl\", 'rb'))\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    print(\"----------------------------\")\n",
    "    print(i)\n",
    "    print(\"----------------------------\")\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred)\n",
    "    rec = recall_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred)\n",
    "    print('Accuracy:', acc)\n",
    "    print('Precision:', prec)\n",
    "    print('Recall:', rec)\n",
    "    print('ROC/AUC:', roc_auc)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
